{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to APIs and LLMs with Python\n",
        "\n",
        "Welcome!\n",
        "In this notebook, we will learn the basics of:\n",
        "- Artificial Intelligence (AI)\n",
        "- Large Language Models (LLMs)\n",
        "- Application Programming Interfaces (APIs)\n",
        "- Python for API interaction\n",
        "- Jupyter Notebook / Google Colab\n",
        "- Saving and sharing with GitHub\n",
        "\n",
        "Let's begin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1: What is Artificial Intelligence (AI)?\n",
        "\n",
        "Artificial Intelligence means teaching computers to think and act like humans.\n",
        "\n",
        "Examples:\n",
        "- Siri or Alexa answering → AI\n",
        "- YouTube recommendations → AI\n",
        "- Self-driving cars → AI\n",
        "\n",
        "So, AI is like giving computers a mini brain. In simple words: AI is automation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions\n",
        "1. Should AI be defined by how it is built, or by what it can do?\n",
        "- Answer: AI should be defined primarily by what it can do rather than how it is built. Its functionality, ability to learn, reason, and make decisions is what truly defines it, while the underlying design is secondary.\n",
        "2. Today's AI is mostly narrow AI (like bots, recommendation systems). What would true 'general AI' look like?\n",
        "- General AI would be able to perform a wide range of tasks with human-like adaptability, learning new skills without specific training. Currently, we are far from achieving it, as existing AI excels only in narrow, specialized tasks.\n",
        "3. Can AI understand things the way humans do, or is it just simulating understanding?\n",
        "- AI does not truly understand; it simulates understanding based on patterns in data. Its responses are predictive rather than conscious or cognitive.\n",
        "4. If an AI system makes a harmful decision, who is responsible: developer, user, or AI?\n",
        "- Responsibility lies with the developers and deployers of the AI system. AI is a tool, and accountability remains with the humans who design, maintain, and operate it.\n",
        "5. Should AI be allowed to make decisions in healthcare, hiring, or law?\n",
        "- AI can assist in these areas but should not have full autonomous control. Humans must oversee critical decisions to ensure fairness, safety, and accountability.\n",
        "6. If AI composes music or art, who owns the rights?\n",
        "- Intellectual property rights usually belong to the programmer or organization that created or trained the AI. AI itself cannot hold legal rights.\n",
        "7. Which jobs will AI change the most in the next 10 years?\n",
        "- AI will impact repetitive, data-driven jobs like customer support and administrative tasks. Jobs requiring creativity, empathy, and complex problem-solving, such as artists or strategists, are hardest to replace.\n",
        "8. Would you trust AI to drive your car, perform surgery, or grade exams?\n",
        "- AI can assist but should not operate fully autonomously without supervision. Trust depends on proven safety and reliability, and human oversight is necessary for unexpected scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2: What are LLMs?\n",
        "\n",
        "LLMs means Large Language Models.\n",
        "They are special computer programs that can read, understand, and write human language.\n",
        "\n",
        "### How do they process and generate text?\n",
        "- *Learning*: The LLM reads books, websites, stories, and articles.\n",
        "- *Understanding*: It analyzes the words in your question.\n",
        "- *Writing*: It guesses the next word step by step.\n",
        "\n",
        "Example: If you say, The sky is... → it predicts: blue.\n",
        "\n",
        "So it answers: The sky is blue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Easy way to remember\n",
        "LLM is like a super-smart parrot:\n",
        "- It has read millions of books.\n",
        "- When you talk to it, it replies by picking the best words it learned before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions\n",
        "1. What task do LLMs perform surprisingly well, and where do they struggle?\n",
        "- LLMs perform well at generating human-like text and answering questions. They struggle with reasoning, commonsense judgment, or up-to-date factual knowledge because they rely on learned patterns rather than true understanding.\n",
        "2. If an LLM gives a confident but wrong answer, is it a mistake or a limitation?\n",
        "- It should be considered a model limitation rather than a human-like mistake. Errors reflect gaps or biases in the training data, not conscious judgment.\n",
        "3. Will LLMs replace programmers, or just change how programming is done?\n",
        "- LLMs are likely to transform programming rather than replace programmers. They automate repetitive coding tasks, but human insight and logic design remain essential.\n",
        "4. Why are humans more data-efficient than LLMs?\n",
        "- Humans are data-efficient because of cognitive abilities like reasoning, contextual understanding, and prior knowledge. LLMs rely purely on statistical patterns and large datasets.\n",
        "5. When an LLM generates a poem, is that creativity?\n",
        "- LLM outputs can appear creative, but this is pattern-based generation rather than true human creativity. The AI lacks intentionality or emotional experience.\n",
        "6. Why might the same question give different answers on different runs?\n",
        "- This shows that LLMs generate probabilistic outputs. They sample from a distribution of likely responses, resulting in variability even for the same prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3: What are APIs?\n",
        "\n",
        "API means Application Programming Interface.\n",
        "\n",
        "Think of an API like a waiter in a restaurant:\n",
        "- You (the customer) give an order.\n",
        "- The waiter takes it to the kitchen (system).\n",
        "- The kitchen prepares it.\n",
        "- The waiter brings it back.\n",
        "\n",
        "Similarly:\n",
        "- You send a request through an API.\n",
        "- The server processes it.\n",
        "- The API brings back the result.\n",
        "\n",
        "*Example*: A weather API can return today's forecast without you opening a website."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4: What is the Role of APIs in Automation?\n",
        "\n",
        "Automation means making machines do work automatically.\n",
        "APIs help automation by letting different programs talk to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 1: Using Weather API\n",
        "- Without API → You open the website and search manually.\n",
        "- With API → A program can automatically fetch data:\n",
        "\n",
        "\"Good morning! Today is sunny.\"\n",
        "\n",
        "You don't have to do anything — it's automatic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Accessing LLMs (like ChatGPT) through API\n",
        "- LLM = big smart brain on a server.\n",
        "- API = the bridge that lets your app talk to that brain.\n",
        "\n",
        "Steps:\n",
        "1. You type: \"Tell me a story about a dragon.\"\n",
        "2. Your app sends this request via API.\n",
        "3. The LLM generates a story.\n",
        "4. The API returns the story to your app.\n",
        "\n",
        "This way, you use the LLM remotely without installing it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Easy way to remember\n",
        "API is like a magic pipe:\n",
        "- One side: You put in your request.\n",
        "- Other side: You get back the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection Questions\n",
        "1. If an AI model is too large for your laptop, how can APIs help?\n",
        "- An API allows your computer to send requests to a remote server where the AI model runs. The server processes the input and returns the output, enabling access without local computing constraints.\n",
        "2. Why do companies (OpenAI, Hugging Face, Google) prefer APIs over downloads?\n",
        "- APIs ensure accessibility, scalability, security, and control over usage. Companies can manage updates and prevent misuse without requiring users to handle large files or complex setups.\n",
        "3. Why do API rate limits exist?\n",
        "- Rate limits prevent server overload, ensure fair usage, and control costs. They may restrict heavy usage but maintain reliability for all users.\n",
        "4. How would you handle a 429 Too Many Requests error?\n",
        "- Implement retry logic with exponential backoff. This approach waits for increasing intervals before retrying, respecting the API limits while keeping the program functional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How it all connects\n",
        "- AI = Smart brain\n",
        "- LLM = AI that talks like humans\n",
        "- API = Messenger/helper\n",
        "- Automation = Work done automatically\n",
        "\n",
        "So whenever you hear:\n",
        "- AI → brain\n",
        "- LLM → talking brain\n",
        "- API → messenger\n",
        "- Automation → automatic work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python for API Interaction\n",
        "\n",
        "## 1. Using requests to call an API\n",
        "Python has a library called requests that helps us talk to APIs (send requests and get answers).\n",
        "\n",
        "Example: Get some data from a public API (a joke API)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Send a GET request to the API\n",
        "response = requests.get(\"https://official-joke-api.appspot.com/random_joke\")\n",
        "\n",
        "# Print raw response (text)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. What is JSON?\n",
        "\n",
        "JSON = JavaScript Object Notation.\n",
        "\n",
        "It's a way to store and share data.\n",
        "Looks like a dictionary in Python → with keys and values.\n",
        "\n",
        "Example JSON from joke API:\n",
        "```json\n",
        "{\n",
        "  \"id\": 123,\n",
        "  \"type\": \"general\",\n",
        "  \"setup\": \"Why did the computer go to the doctor?\",\n",
        "  \"punchline\": \"Because it caught a virus!\"\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Handling JSON in Python\n",
        "We use .json() method to turn the API response into a Python dictionary.\n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Call the API\n",
        "response = requests.get(\"https://official-joke-api.appspot.com/random_joke\")\n",
        "\n",
        "# Convert to Python dictionary\n",
        "data = response.json()\n",
        "\n",
        "# Access parts of the JSON\n",
        "print(\"Setup:\", data[\"setup\"])\n",
        "print(\"Punchline:\", data[\"punchline\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Activities: APIs + Python + LLMs\n",
        "\n",
        "### Activity 1: Set up Python Environment\n",
        "- **Option A: Google Colab (recommended)**\n",
        "  1. Go to [Google Colab](https://colab.research.google.com/)\n",
        "  2. Click New Notebook\n",
        "  3. Start coding in Python immediately\n",
        "\n",
        "- **Option B: Local Setup (advanced)**\n",
        "  1. Install Anaconda (includes Jupyter Notebook)\n",
        "  2. Open Jupyter Notebook and start coding\n",
        "\n",
        "---\n",
        "### Activity 2: Sign Up for Groq API\n",
        "1. Go to [console.groq.com](https://console.groq.com)\n",
        "2. Make a free account\n",
        "3. Find your API Key (a secret password for using Groq)\n",
        "   - Copy it → use in Python\n",
        "   - Keep it safe! Never share it publicly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Groq Account, Notebook, and GitHub\n",
        "\n",
        "### Part 1: Google Colab (Easiest)\n",
        "1. Go to [Google Colab](https://colab.research.google.com/)\n",
        "2. Click New Notebook\n",
        "3. Run code with Shift+Enter\n",
        "4. Install packages: `!pip install groq`\n",
        "\n",
        "### Part 2: Local Setup with Jupyter Notebook\n",
        "1. Install [Anaconda](https://www.anaconda.com/) (includes Python + Jupyter)\n",
        "2. Launch Jupyter Notebook\n",
        "3. Create new Python 3 notebook and run code\n",
        "\n",
        "### Part 3: GitHub + Notebooks\n",
        "1. Install Git\n",
        "2. Create GitHub account & repository\n",
        "3. Connect notebook to GitHub with `git add`, `commit`, `push`\n",
        "\n",
        "Or upload via GitHub website → Upload Files → drag & drop your .ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practice Examples\n",
        "\n",
        "## Example 1: Simple API Call Practice\n",
        "Let's practice with a free API that doesn't need authentication:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install requests if needed (for Colab)\n",
        "# !pip install requests\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Try a cat fact API\n",
        "response = requests.get(\"https://catfact.ninja/fact\")\n",
        "cat_fact = response.json()\n",
        "\n",
        "print(\"Cat Fact:\")\n",
        "print(cat_fact[\"fact\"])\n",
        "print(f\"Length: {cat_fact['length']} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Working with Groq API\n",
        "Once you have your Groq API key, you can interact with LLMs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Groq library\n",
        "# !pip install groq\n",
        "\n",
        "from groq import Groq\n",
        "\n",
        "# Replace 'your-api-key-here' with your actual Groq API key\n",
        "client = Groq(api_key=\"your-api-key-here\")\n",
        "\n",
        "# Send a message to the LLM\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain what an API is in one sentence.\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "\n",
        "print(\"LLM Response:\")\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Error Handling\n",
        "Always handle potential errors when working with APIs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def safe_api_call(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raises an exception for bad status codes\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error calling API: {e}\")\n",
        "        return None\n",
        "    except ValueError as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test with a working API\n",
        "result = safe_api_call(\"https://httpbin.org/json\")\n",
        "if result:\n",
        "    print(\"Success!\", result)\n",
        "else:\n",
        "    print(\"API call failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resources\n",
        "\n",
        "## Documentation & Tutorials\n",
        "- [Groq API Docs](https://console.groq.com/docs)\n",
        "- [Python requests Library](https://requests.readthedocs.io/en/latest/)\n",
        "- [W3Schools JSON Tutorial](https://www.w3schools.com/js/js_json_intro.asp)\n",
        "- [GitHub Docs: Hello World](https://docs.github.com/en/get-started/quickstart/hello-world)\n",
        "\n",
        "## Free APIs to Practice With\n",
        "- [JSONPlaceholder](https://jsonplaceholder.typicode.com/) - Fake REST API\n",
        "- [Cat Facts API](https://catfact.ninja/) - Random cat facts\n",
        "- [JokeAPI](https://jokeapi.dev/) - Programming and general jokes\n",
        "- [REST Countries](https://restcountries.com/) - Country information\n",
        "\n",
        "## Next Steps\n",
        "1. **Practice**: Try different APIs and experiment with the code\n",
        "2. **Build**: Create a simple project that combines multiple APIs\n",
        "3. **Learn**: Explore more advanced topics like authentication, rate limiting\n",
        "4. **Share**: Upload your notebooks to GitHub and share your learning journey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary\n",
        "\n",
        "Congratulations! You've learned:\n",
        "\n",
        "**AI & LLMs**: What they are and how they work  \n",
        "**APIs**: The bridges that connect different systems  \n",
        "**Python**: Using requests library to interact with APIs  \n",
        "**JSON**: How data is structured and exchanged  \n",
        "**Tools**: Setting up Colab, Jupyter, and GitHub  \n",
        "\n",
        "## Key Takeaways\n",
        "- **AI** = Smart automation\n",
        "- **LLM** = AI that understands and generates human language\n",
        "- **API** = Messenger between different programs\n",
        "- **Python + requests** = Easy way to talk to APIs\n",
        "- **JSON** = Common data format for APIs\n",
        "\n",
        "## What's Next?\n",
        "- Experiment with different APIs\n",
        "- Build your own projects\n",
        "- Learn about API authentication and security\n",
        "- Explore more advanced LLM techniques\n",
        "\n",
        "Happy coding!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
